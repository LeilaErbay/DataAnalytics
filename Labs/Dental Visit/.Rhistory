?tible
??tible
?read_excel
?readxl
?class
?typeof
which.max
?which.max
?sample
?set.seed
.Random.seed?
?.Random.seed
?binomial
?rbinom
trials <- numeric(length = 100)
#sum(rbinom(20,20, 0.618))
for(i in seq_along(trials)){
trials[i] <- sum(rbinom(1,20, 0.618))
}
trials <- numeric(length = 100)
#sum(rbinom(20,20, 0.618))
for(i in seq_along(trials)){
trials[i] <- sum(rbinom(1,20, 0.618))
}
hist(trials)
?binom?
?binom
?binom
trials <- numeric(length = 100)
#sum(rbinom(20,20, 0.618))
for(i in seq_along(trials)){
trials[i] <- sum(rbinom(20,1, 0.618))
}
hist(trials)
#
hist(rbinom(20,100, 0.618))
#
hist(sum(rbinom(20,100, 0.618)))
#
hist(rbinom(20,100, 0.618))
trials <- numeric(length = 100)
#sum(rbinom(20,20, 0.618))
for(i in seq_along(trials)){
trials[i] <- sum(rbinom(20,1, 0.618))
}
hist(trials)
mean(trials)
trials <- numeric(length = 1000)
#sum(rbinom(20,20, 0.618))
for(i in seq_along(trials)){
trials[i] <- sum(rbinom(20,1, 0.618))
}
mean(trials)
hist(trials)
trials <- numeric(length = 100)
#sum(rbinom(20,20, 0.618))
for(i in seq_along(trials)){
trials[i] <- sum(rbinom(20,1, 0.618))
}
mean(trials)
hist(trials)
var(trials)
trialsOt <- numeric(length=100)
for(i in seq_along(trialsOt)){
trialsOt[i] <- sum(rbinom(15,1,.414))
}
mean(trialsOt)
var(trialsOt)
meanW <- 3*meanOt + 2*meanOb + 10
varW <- 9*varOt + 4*varOb + 100
#p = 0.618
#n = 20
#size = 20
#
hist(rbinom(20,100, 0.618))
trials <- numeric(length = 100)
#sum(rbinom(20,20, 0.618))
for(i in seq_along(trials)){
trials[i] <- sum(rbinom(20,1, 0.618))
}
meanOb <-mean(trials)
varOb <-var(trials)
hist(trials)
#
trialsOt <- numeric(length=100)
for(i in seq_along(trialsOt)){
trialsOt[i] <- sum(rbinom(15,1,.414))
}
meanOt <-mean(trialsOt)
varOt <-var(trialsOt)
meanW <- 3*meanOb + 2*meanOt + 10
varW <- 9*varOb + 4*varOt + 100
varW <- 9*varOb + 4*varOt
n <- 1:15
ifelse(n %% 3 ==0 , "divisible by 3", "not divisible by 3")
df <- c(n,NULL)
df <- as.data.frame(c(n,NULL))
View(df)
df <- as.data.frame(c(n,result))
n <- 1:15
result <- NULL
df <- as.data.frame(c(n,result))
df <- as.data.frame(n)
View(df)
df <- cbind(NULL)
df <- cbind(result)
df <- as.data.frame(n)
df <- cbind(result)
df <- cbind(result)
result <- NA
df <- as.data.frame(n)
df <- cbind(result)
View(df)
df <- as.data.frame(n)
result <-ifelse(n %% 3 ==0 , "divisible by 3", "not divisible by 3")
df <- cbind(as.data.frame(result))
View(df)
n <- 1:15
df <- as.data.frame(n)
result <-ifelse(n %% 3 ==0 , "divisible by 3", "not divisible by 3")
df[,2] <- cbind(as.data.frame(result))
n <- 1:15
df <- as.data.frame(n)
df[,2] <- ifelse(n %% 3 ==0 , "divisible by 3", "not divisible by 3")
View(df)
?seq
?matrix
x <- matrix(NULL, 5,5)
for(i in 1:nrow(x)) {
for(j in 1:ncol(x)) {
x[i,j] <- (i+j)^2
}
x <- matrix(NULL, 5,5)
for(i in 1:nrow(x)) {
for(j in 1:ncol(x)) {
x[i,j] <- (i+j)^2
}
}
source('~/.active-rstudio-document', echo=TRUE)
x <- matrix(NULL, 5,5)
x <- matrix(NULL, 5,5)
x <- matrix(NA, 5,5)
x <- matrix(NA, 5,5)
for(i in 1:nrow(x)) {
for(j in 1:ncol(x)) {
x[i,j] <- (i+j)^2
}
}
View(x)
x <- matrix(NA, 5,5)
View(x)
for(i in 1:nrow(x)) {
for(j in 1:ncol(x)) {
x[i,j] <- (i+j)^2
}
}
df <- cbind(df,ifelse(n %% 3 ==0 , "divisible by 3", "not divisible by 3"))
n <- 1:15
df <- as.data.frame(n)
df <- cbind(df,ifelse(n %% 3 ==0 , "divisible by 3", "not divisible by 3"))
View(df)
lapply(list, function)
lapply
#### F TEST
var2 <- 3.42^2
var1 <- 3.63^2
f_test <-var2/var1   #var2 < var1
#df = 49, 49
pval <- pf(var2/var1, 49, 49, lower.tail = T)
pval2 <- pf(var1/var2, 49, 49, lower.tail= F)
getwd()
install.packages("RMySQL")
install.packages("RPostgreSQL")
install.packages
install.packages("RSQLite")
install.packages("sqldf")
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 3306, dbname='Level Database')
library(RMySQL)
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 3306, dbname='Level Database')
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 443, dbname='Level Database')
;
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 3306, dbname='Level Database');
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 3306, dbname='Level Database');
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 3306, dbname='lerbay_edx');
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 3306, dbname='lerbay_zoo_lab');
dbtables <- dbListTables(conn)
dbtables
conn <- dbConnect(MySQL(), user = 'lerbay', password = 'tJU7dnLQ',
host = 'da2017septft.cks5ya9qdcwp.us-east-2.rds.amazonaws.com',
port = 3306, dbname='lerbay_zoo_lab');
dbtables <- dbListTables(conn)
dbtables
weeks_per_anm <- dbReadTable(conn, 'weeks_per_anm')
View(weeks_per_anm)
plot(weeks_per_anm$cal_date, weeks_per_anm$weight, type = 'l')
typeof(weeks_per_anm$cal_date)
asDate(weeks_per_anm$cal_date)
as.Date(weeks_per_anm$cal_date)
weeks_per_anm$cal_date <- as.Date(weeks_per_anm$cal_date)
plot(weeks_per_anm$cal_date, weeks_per_anm$weight, type = 'l')
?plot
library(ggplot2)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, color= id))
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, fill= id))
print(p)
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, color= id))
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, color= id, group = id))
print(p)
p <- ggplot(data = weeks_per_anm, aes(x = cal_date, y = weight, color= id, group = id)) +
geom_line()
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, color= id, group = id))
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, color= id, group = id))
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, color= id))
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, linetype= id))
print(p)
p <- ggplot(data = weeks_per_anm) +
geom_line(aes(x = cal_date, y = weight, group= id))
print(p)
data("iris")
iris.predicted <- iris
for(i in seq(along = iris.predicted$Petal.Length)) {
if (iris.predicted$Petal.Length[i] < 3) {
iris.predicted$Pred[i] <- 'setosa'
}
else if (iris.predicted$Petal.Length[i] < 5) {
iris.predicted$Pred[i] <- 'versicolor'
}
else {
iris.predicted$Pred[i] <- 'virginica'
}
}
data(iris)
irisNum = iris[,-5]
names(irisNum)
ssPercantge = numeric(10)
## want clusters to have small ingroup variance and large out group variance
for (k in 1:10){
km = kmeans(irisNum, centers = k)
outGpSS = km$betweenss
totSS = km$totss
ssPerc = outGpSS/totSS
ssPercentage[k] = ssPerc
}
ssPercentage = numeric(10)
## want clusters to have small ingroup variance and large out group variance
for (k in 1:10){
km = kmeans(irisNum, centers = k)
outGpSS = km$betweenss
totSS = km$totss
ssPerc = outGpSS/totSS
ssPercentage[k] = ssPerc
}
plot(ssPercentage, type = 'p')
lines(ssPercentage)
##SCALING DATA = STANDARDIZE DATA FOR YOU
irisNum = scale(irisNum)
## want clusters to have small ingroup variance and large out group variance
for (k in 1:10){
km = kmeans(irisNum, centers = k)
outGpSS = km$betweenss
totSS = km$totss
ssPerc = outGpSS/totSS
ssPercentage[k] = ssPerc
}
plot(ssPercentage, type = 'p')
lines(ssPercentage)
## Princomp
PCA = princomp(irisNum)
str(PCA)
plot(PCA)
plot(PCA, type = 'l')
PCs = PCA$scores[,1:3]
## By clustering method
# remove species from the data to cluster
iris2 <- iris[, 1:4]
## By clustering method
# remove species from the data to cluster
iris2 <- iris[, 1:4]
summary(iris2)
# Run clustering for three clusters
kmeans.result <- kmeans(iris2, centers = 3)
# cluster centers
kmeans.result$centers
# cluster IDs
kmeans.result$cluster
# Get the centers
centers <- kmeans.result$centers[kmeans.result$cluster, ]
View(centers)
View(centers)
# Calculate distances between objects and cluster centers
distances <- sqrt(rowSums((iris2 - centers)^2))
# Apply univariate outlier detection to distances
outlierValues <- boxplot.stats(distances)$out
boxplot(distances)
outliers <- which(distances %in% outlierValues)
# plot clusters
plot(iris2[, c("Sepal.Length", "Sepal.Width")],
pch = "o",
col = kmeans.result$cluster,
cex = 0.8,
main = "Iris clusters and outliers")
# plot cluster centers
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")],
col = 1:3,
pch = 10,
cex = 2.5)
# plot outliers
points(iris2[outliers, c("Sepal.Length", "Sepal.Width")],
pch = "+",
col = 4,
cex = 1.5)
# Explore the data
train = read.csv("DentalVisit-Train.csv")
# Explore the data
setwd('/Users/LeilaErbay/Desktop/LevelNeu2018/Labs/Dental Visit')
train = read.csv("DentalVisit-Train.csv")
dim(train)
str(train)
##  Isolate numeric variables for exploration. We'll explore the factors later.
summary(train[,c("confident","bmi","children")])
max.bmi <- max(train$bmi, na.rm = TRUE)
?na.action
bmi.omit <- na.omit(train$bmi[train$bmi < max.bmi])
max(train$bmi, na.rm=TRUE)
max(bmi.omit, na.rm=TRUE)
par(mfrow=c(1,2))
# Without missing value filtered
hist(train$bmi,
col="darkblue",
main="History of bmi (full)",
cex.axis = 1.5,
cex.lab = 1.5)
# With missing value filtered
hist(bmi.omit,
col="darkgreen",
main="History of bmi (Outlier Removed)",
cex.axis = 1.5,
cex.lab = 1.5)
hist(log(bmi.omit),
col="darkgreen",
main="History of bmi (Outlier Removed)",
cex.axis = 1.5,
cex.lab = 1.5)
hist(bmi.omit,
col="darkgreen",
main="History of bmi (Outlier Removed)",
cex.axis = 1.5,
cex.lab = 1.5)
hist(log(bmi.omit),
col="darkgreen",
main="History of bmi (Outlier Removed)",
cex.axis = 1.5,
cex.lab = 1.5)
## Let's take a look at the categorical variables.
summary(train[,!(names(train) %in% c("confident","bmi","children"))])
table(train$agegrp)
barplot(table(train$agegrp),
col="darkgreen",
main = "Age group distribution",
las = 2)
# Create racial percentage table
age.tbl <- table(train$agegrp)
age.perc <- round(100*age.tbl/sum(age.tbl),2)
barplot(age.perc,
col = "darkgreen",
main = "Age group distribution",
ylab = "%", las = 2)
plot(train[which( train$children > 0 & train$bmi < 55), ]$children,
train[which( train$children > 0 & train$bmi < 55), ]$bmi,
ylab = "BMI",
xlab = "Number of children",
main = "BMI vs # Children",
col="darkgreen",
type = "p")
plot(jitter(train[which( train$children > 0 & train$bmi < 55), ]$children,
amount = .45),
train[which( train$children > 0 & train$bmi < 55), ]$bmi,
ylab = "BMI",
xlab = "Number of children (Jittered)",
main = "BMI vs # Children",
col="darkblue",
type = "p")
#bmi vs. race boxplots
par(mfrow=c(1,1))
boxplot(bmi ~ race,
data = train[train$bmi < 60,],
xlab = "Race",
ylab = "BMI",
col = "darkred")
# Check distribution of age group over race
ageByRace = table(train$agegrp, train$race)
ageByRace
ageByRace = t(t(ageByRace) / colSums(ageByRace))
ageByRace = round(t(t(ageByRace) / colSums(ageByRace)),2)
ageByRace
# Sanity Check:
colSums(ageByRace)
# print number of lines with missing values
sum(rowSums(is.na(train)) > 0)
sum(rowSums(is.na(train)) > 0) / nrow(train)
rowSums(is.na(train))
# print columns with missing values
colSums(is.na(train))
# Number of missing values for "meds" (37)
nbr.misg <- sum(is.na(train$meds))
# Find useful variables:
colSums(is.na(train[is.na(train$meds),]))
# library(MASS)
MedsReg <- glm(meds ~ ., family = binomial, data = na.omit(train[,-1]))
# Modeling results summary
summary(MedsReg)
# Extract the temporary data for logistic regression modeling
mod.train <- subset(train, select = c("meds", "sex", "insured"))
# Model training
MedsReg <- glm(meds ~ sex + insured,
family = binomial,
data = na.omit(mod.train))
# Model training
MedsReg <- glm(meds ~ sex + insured,
family = binomial,
data = na.omit(mod.train))
# Modeling results summary
summary(MedsReg)
# Fill in the missing values of 'meds' with estimated values from the model
newMeds <- train$meds
# Estimate meds value using the model
z <- predict(MedsReg, train, type = 'response')
summary(z)
newMeds[is.na(train$meds)] <- ifelse(z[is.na(train$meds)]>=0.5,"Yes","No")
# Number of missing values after imputation dropped to 0
nbr.misg.new <- sum(is.na(newMeds))
nbr.misg.new
install.packages("MASS")
library(MASS)
train <- read.csv("DentalVisit-Clean.csv")
train$healthgroup <- addNA(train$healthgroup)
train$agegrp <- addNA(train$agegrp)
train$race <- addNA(train$race)
train$employ.ins <- addNA(train$employ.ins)
train$insured <- addNA(train$insured)
train$employ <- addNA(train$employ)
train$marital.stat <- addNA(train$marital.stat)
train$postponed.care <- addNA(train$postponed.care)
train$emergency <- addNA(train$emergency)
train$specialist <- addNA(train$specialist)
train$meds <- addNA(train$meds)
train$health <- addNA(train$health)
train$educ <- addNA(train$educ)
anova(m1,m2,test='Chisq')
#
#
m1 <- glm(dental.visit ~ meds+emergency,data=train,family=binomial)
m2 <- glm(dental.visit~meds*emergency,data=train,family=binomial)
anova(m1,m2,test='Chisq') ## LIKELIHOOD RATIO TEST
train$log.bmi <- log(train$bmi)
# Set dental.visit from "Yes"/"No" to 1/0 (This makes it easier to work with)
train$dental.visit <- ifelse(train$dental.visit == "Yes", 1, 0)
# Fit model with all interesting features and theorized interactions
base1 <- glm(dental.visit ~ phone + sex + agegrp + race + employ.ins + insured +
employ + marital.stat + postponed.care + emergency +
specialist + meds + log.bmi + children + confident +
educ + health + log.bmi + phone:confident +
employ.ins:specialist + sex:marital.stat +
race:employ,
data=train,
family = "binomial")
# install.packages("MASS")
library(MASS)
stepsDental <- stepAIC(base1, direction="both")
stepsDental <- stepAIC(base1, direction="both")
# Create predicted response from training set
y <- round(predict(stepsDental, train, type="response"))
# install.packages("caret")
# install.packages("e1071")
library(caret)
install.packages("caret")
install.packages("e1071")
#install.packages("caret")
#install.packages("e1071")
library(caret)
library(e1071)
confusionMatrix(table(data.frame(train$dental.visit, y)))
confusionMatrix(table(data.frame(train$dental.visit, y)))
